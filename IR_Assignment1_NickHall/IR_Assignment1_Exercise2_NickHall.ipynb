{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "https://en.wikipedia.org/wiki/Tf%E2%80%93idf\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "MVFOfzd3NQBO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kTtAh-m2NFuf",
        "outputId": "fe5eb71e-e080-4786-c7fb-3571a26a9348"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Automatic pdb calling has been turned OFF\n",
            "Automatic pdb calling has been turned ON\n"
          ]
        }
      ],
      "source": [
        "# Testing the debug mode\n",
        "%pdb off\n",
        "%pdb on"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## a."
      ],
      "metadata": {
        "id": "i44OEL8TSyQV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf_idf_string = \"\"\"\n",
        "In information retrieval, tf–idf (also TF*IDF, TFIDF, TF–IDF, or Tf–idf), short for term frequency–inverse document frequency, is a numerical statistic that is intended to reflect how important a word is to a document in a collection or corpus. It is often used as a weighting factor in searches of information retrieval, text mining, and user modeling. The tf–idf value increases proportionally to the number of times a word appears in the document and is offset by the number of documents in the corpus that contain the word, which helps to adjust for the fact that some words appear more frequently in general.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "I5gqWb0LS2Wy"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## b."
      ],
      "metadata": {
        "id": "ezvpGK0HTH7S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words = tf_idf_string.split(\" \")\n",
        "# Hover the mouse on words and see the value\n",
        "print(\"Total words: \")\n",
        "print(len(words))\n",
        "print(\"Total unique words: \")\n",
        "print(len(set(words)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HCnbKkzPTMi6",
        "outputId": "cbcb71d6-356c-456f-bf6d-98873b6d6565"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total words: \n",
            "102\n",
            "Total unique words: \n",
            "67\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## c. "
      ],
      "metadata": {
        "id": "wd7a7KXd9-kU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "counter_words = dict(Counter(words))\n",
        "sorted_by_value = dict(sorted(counter_words.items(), key=lambda item: item[1], reverse=True))\n",
        "print(\"The most frequent word is \\\"\" + list(sorted_by_value.keys())[0] +\"\\\" showing up \"+ str(list(sorted_by_value.values())[0])+ \" times\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oydZ88gR-EBA",
        "outputId": "6000aea9-2c20-410e-8fcc-f59c157a7975"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The most frequent word is \"a\" showing up 6 times\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## d. "
      ],
      "metadata": {
        "id": "8eHqdVfyAGtV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('TFIDF.txt', 'r') as f:\n",
        "    file_content = f.read()\n",
        "words = file_content.split(\" \")\n",
        "# Hover the mouse on words and see the value\n",
        "print(len(words))\n",
        "print(len(set(words)))\n",
        "\n",
        "from collections import Counter\n",
        "counter_words = dict(Counter(words))\n",
        "sorted_by_value = dict(sorted(counter_words.items(), key=lambda item: item[1], reverse=True))\n",
        "print(\"The most repeated word is \\\"\" + list(sorted_by_value.keys())[0] +\"\\\" with frequency of \"+ str(list(sorted_by_value.values())[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0DggN7QTnYm",
        "outputId": "ebb9584d-94ab-4ee4-e88b-38fa01fcf691"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "102\n",
            "67\n",
            "The most repeated word is \"a\" with frequency of 6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## e. "
      ],
      "metadata": {
        "id": "7atPbH9vUXoU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install nltk"
      ],
      "metadata": {
        "id": "I6ELcyFAUbm0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f30434eb-e935-4c3a-8a29-a54cbcd184df"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.7)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk) (4.64.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk) (1.1.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk) (2022.6.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "nltk.download('stopwords')\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from collections import Counter\n",
        "\n",
        "def print_most_frequent_word(words):\n",
        "  counter_words = dict(Counter(words))\n",
        "  sorted_by_value = dict(sorted(counter_words.items(), key=lambda item: item[1], reverse=True))\n",
        "  print(\"The most frequent word is \\\"\" + list(sorted_by_value.keys())[0] +\"\\\" showing up \"+ str(list(sorted_by_value.values())[0]) + \" times\")\n",
        "\n",
        "\n",
        "filtered_words = [word for word in words if word not in stopwords.words('english')]\n",
        "print_most_frequent_word(words)\n",
        "print_most_frequent_word(filtered_words)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9GXOi_JcV2K1",
        "outputId": "b71d03fc-9280-42d0-a4f5-5b4712df15a3"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The most frequent word is \"a\" showing up 6 times\n",
            "The most frequent word is \"document\" showing up 3 times\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    }
  ]
}